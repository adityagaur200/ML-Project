{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a74c7-50be-410b-bcf3-5f695b5da22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.5786 - loss: 1.1746\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51935, saving model to models/cnn-parameters-improvement-01-0.52.keras\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 515ms/step - accuracy: 0.5789 - loss: 1.1689 - val_accuracy: 0.5194 - val_loss: 0.7013\n",
      "Epoch 2/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 0.7154 - loss: 0.5660\n",
      "Epoch 2: val_accuracy improved from 0.51935 to 0.70000, saving model to models/cnn-parameters-improvement-02-0.70.keras\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 474ms/step - accuracy: 0.7157 - loss: 0.5654 - val_accuracy: 0.7000 - val_loss: 0.6096\n",
      "Epoch 3/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 0.7711 - loss: 0.4652\n",
      "Epoch 3: val_accuracy improved from 0.70000 to 0.75484, saving model to models/cnn-parameters-improvement-03-0.75.keras\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 476ms/step - accuracy: 0.7713 - loss: 0.4652 - val_accuracy: 0.7548 - val_loss: 0.5533\n",
      "Epoch 4/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - accuracy: 0.8315 - loss: 0.3924\n",
      "Epoch 4: val_accuracy did not improve from 0.75484\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 477ms/step - accuracy: 0.8313 - loss: 0.3925 - val_accuracy: 0.6806 - val_loss: 0.5556\n",
      "Epoch 5/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - accuracy: 0.8600 - loss: 0.3202\n",
      "Epoch 5: val_accuracy improved from 0.75484 to 0.78387, saving model to models/cnn-parameters-improvement-05-0.78.keras\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 476ms/step - accuracy: 0.8599 - loss: 0.3205 - val_accuracy: 0.7839 - val_loss: 0.4830\n",
      "Epoch 6/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - accuracy: 0.8189 - loss: 0.3970\n",
      "Epoch 6: val_accuracy improved from 0.78387 to 0.79677, saving model to models/cnn-parameters-improvement-06-0.80.keras\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 480ms/step - accuracy: 0.8186 - loss: 0.3974 - val_accuracy: 0.7968 - val_loss: 0.4178\n",
      "Epoch 7/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - accuracy: 0.8603 - loss: 0.3124\n",
      "Epoch 7: val_accuracy did not improve from 0.79677\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 481ms/step - accuracy: 0.8607 - loss: 0.3122 - val_accuracy: 0.7774 - val_loss: 0.4142\n",
      "Epoch 8/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - accuracy: 0.8690 - loss: 0.2904\n",
      "Epoch 8: val_accuracy improved from 0.79677 to 0.82258, saving model to models/cnn-parameters-improvement-08-0.82.keras\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 503ms/step - accuracy: 0.8690 - loss: 0.2905 - val_accuracy: 0.8226 - val_loss: 0.4165\n",
      "Epoch 9/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - accuracy: 0.8788 - loss: 0.2870\n",
      "Epoch 9: val_accuracy improved from 0.82258 to 0.83548, saving model to models/cnn-parameters-improvement-09-0.84.keras\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 490ms/step - accuracy: 0.8790 - loss: 0.2868 - val_accuracy: 0.8355 - val_loss: 0.3530\n",
      "Epoch 10/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.9124 - loss: 0.2109\n",
      "Epoch 10: val_accuracy did not improve from 0.83548\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 514ms/step - accuracy: 0.9122 - loss: 0.2113 - val_accuracy: 0.8000 - val_loss: 0.3963\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "IMG_WIDTH, IMG_HEIGHT = 240, 240\n",
    "\n",
    "# Function to crop brain contour\n",
    "def crop_brain_contour(image, plot=False):\n",
    "    # Convert the image to grayscale, and blur it slightly\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Threshold the image, then perform a series of erosions + dilations to remove any small regions of noise\n",
    "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Find contours and grab the largest one\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    # Find the extreme points (left, right, top, bottom)\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "    # Crop the new image out of the original image using the four extreme points\n",
    "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title('Original Image')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(new_image)\n",
    "        plt.title('Cropped Image')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return new_image\n",
    "\n",
    "# Function to load data\n",
    "def load_data(dir_list, image_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    image_width, image_height = image_size\n",
    "\n",
    "    for directory in dir_list:\n",
    "        for filename in os.listdir(directory):\n",
    "            image = cv2.imread(directory + '\\\\' + filename)\n",
    "            image = crop_brain_contour(image, plot=False)\n",
    "            image = cv2.resize(image, (image_width, image_height))\n",
    "            image = image / 255.0  # Normalize\n",
    "            X.append(image)\n",
    "            if directory[-3:] == 'yes':\n",
    "                y.append([1])\n",
    "            else:\n",
    "                y.append([0])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Function to split data\n",
    "def split_data(X, y, test_size=0.2):\n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Build the model\n",
    "def build_model(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((2, 2))(X_input)\n",
    "    X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((4, 4), name='max_pool0')(X)\n",
    "    X = MaxPooling2D((4, 4), name='max_pool1')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='BrainDetectionModel')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to predict using the model\n",
    "def predict_image(model, image_path):\n",
    "    # Attempt to load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Error: Image could not be loaded. Please check the file path.\")\n",
    "        return\n",
    "    \n",
    "    # Crop and process the image\n",
    "    image = crop_brain_contour(image, plot=False)\n",
    "    image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    prediction = model.predict(image)\n",
    "    \n",
    "    # Return the result\n",
    "    if prediction > 0.5:\n",
    "        return \"Brain Tumor Detected\"\n",
    "    else:\n",
    "        return \"No Brain Tumor Detected\"\n",
    "\n",
    "# Main function to train the model\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the paths for training data\n",
    "    augmented_path = 'augmented data/'\n",
    "    augmented_yes = augmented_path + 'yes'\n",
    "    augmented_no = augmented_path + 'no'\n",
    "\n",
    "    # Load data\n",
    "    X, y = load_data([augmented_yes, augmented_no], (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    # Split data into training, validation, and test sets\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)\n",
    "\n",
    "    # Build and compile the model\n",
    "    IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "    model = build_model(IMG_SHAPE)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    log_file_name = f'brain_tumor_detection_cnn_{int(time.time())}'\n",
    "    tensorboard = TensorBoard(log_dir=f'logs/{log_file_name}')\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=\"models/cnn-parameters-improvement-{epoch:02d}-{val_accuracy:.2f}.keras\",\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=32,\n",
    "        epochs=10,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[tensorboard, checkpoint]\n",
    "    )\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save(\"models/cnn_model.keras\")\n",
    "\n",
    "    # Take user input and make prediction\n",
    "    user_image_path = input(\"Enter the path to the image for prediction: \")\n",
    "    prediction = predict_image(model, user_image_path)\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064b39cf-aec3-4577-b98f-ecae51757c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
